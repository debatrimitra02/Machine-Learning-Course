
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>bayesian_regression</title><meta name="generator" content="MATLAB 8.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2014-11-20"><meta name="DC.source" content="bayesian_regression.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#3">do Bayesian regression</a></li><li><a href="#4">draw samples from posterior</a></li><li><a href="#5">get mean from posterior</a></li><li><a href="#6">plot histograms</a></li><li><a href="#8">save plots</a></li><li><a href="#9">plot Monte Carlo trace plots</a></li></ul></div><pre class="codeinput"><span class="keyword">function</span> bayesian_regression(X,Y,small_sigma_squared,eta_sqaured)
</pre><pre class="codeinput"><span class="comment">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>
<span class="comment">% Name - bayesian_regression</span>
<span class="comment">% Creation Date - 3rd Nov 2014</span>
<span class="comment">% Author: Soumya Banerjee</span>
<span class="comment">% Website: https://sites.google.com/site/neelsoumya/</span>
<span class="comment">%</span>
<span class="comment">% Description:</span>
<span class="comment">%   Function to do Bayesian regression</span>
<span class="comment">%   inspired by video on bayesian linear regression</span>
<span class="comment">%   https://www.youtube.com/watch?v=qz2U8coNwV4</span>
<span class="comment">%   by mathematicalmonk on youtube</span>
<span class="comment">%</span>
<span class="comment">% Input:</span>
<span class="comment">%       X - matrix of predictors</span>
<span class="comment">%       Y - vector of responses</span>
<span class="comment">%       small_sigma_squared - standard deviation^2 (variance) for covariance matrix for Y</span>
<span class="comment">%       eta_sqaured - standard deviation^2 (variance) for covariance matrix for beta (regressors)</span>
<span class="comment">%</span>
<span class="comment">% Output:</span>
<span class="comment">%       1) Vector of inferred regressors/parameters</span>
<span class="comment">%       2) Histograms of inferred regressors/parameters</span>
<span class="comment">%       3) Monte Carlo trace plots</span>
<span class="comment">%</span>
<span class="comment">% Assumptions -</span>
<span class="comment">%</span>
<span class="comment">% Example usage:</span>
<span class="comment">%   X = randn(100,5)</span>
<span class="comment">%   r = [0;2;0;-3;0] % only two nonzero coefficients</span>
<span class="comment">%   Y = X*r + randn(100,1)*.1 % small added noise</span>
<span class="comment">%   small_sigma_squared = 0.01</span>
<span class="comment">%   eta_sqaured = 0.01</span>
<span class="comment">%   bayesian_regression(X,Y,small_sigma_squared,eta_sqaured)</span>
<span class="comment">%</span>
<span class="comment">% License - BSD</span>
<span class="comment">%</span>
<span class="comment">% Acknowledgements -</span>
<span class="comment">%           Dedicated to my wife Joyeeta Ghose and my mother Kalyani</span>
<span class="comment">%           Banerjee</span>
<span class="comment">%</span>
<span class="comment">% Change History -</span>
<span class="comment">%                   3rd  Nov 2014  - Creation by Soumya Banerjee</span>
<span class="comment">%                   20th Nov 2014  - Modified by Soumya Banerjee</span>
<span class="comment">%                                       no burn-in required; hence taken</span>
<span class="comment">%                                       out (thanks to suggestion by</span>
<span class="comment">%                                       Alireza Kashani)</span>
<span class="comment">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>


tic;
</pre><h2>do Bayesian regression<a name="3"></a></h2><p>beta is vector of regressors P(beta|D) ~ N(beta| mu, lambda) mu = lambda * X{transpose} * big_sigma^(-1) * Y lambda = (X{transpose} * inv(sigma) * X + inv(big_omega))^{-1} <img src="bayesian_regression_eq10690854483587142809.png" alt="$P(\beta|D) \sim N(\beta| \mu, \lambda)$"> <img src="bayesian_regression_eq14956070084965665838.png" alt="$\mu = \Lambda * X^{T} * \Sigma^{-1} * Y$"> <img src="bayesian_regression_eq17186608452422724420.png" alt="$\Lambda = (X^{T} * \Sigma^{-1} * X + \Omega^{-1})^{-1}$"></p><pre class="codeinput">iNumMeasurements = size(X,1);
iNumRegressors   = size(X,2);

big_sigma = small_sigma_squared * eye(iNumMeasurements); <span class="comment">%a = 0.01 * eye(5);</span>
big_omega = eta_sqaured * eye(iNumRegressors); <span class="comment">%b = 0.01 * eye(5);</span>

disp(<span class="string">'covariance matrix and mean vector of posterior distribution'</span>)
lambda = inv(X' * inv(big_sigma) * X + inv(big_omega))
mu     = lambda * X' * inv(big_sigma) * Y

<span class="comment">% mvnrnd(MU,SIGMA)</span>
<span class="comment">% mvnrnd(mu,lambda)</span>
</pre><pre class="codeoutput">covariance matrix and mean vector of posterior distribution

lambda =

   1.0e-03 *

    0.0930   -0.0041   -0.0036   -0.0036   -0.0106
   -0.0041    0.1179   -0.0003    0.0049    0.0176
   -0.0036   -0.0003    0.0847    0.0016   -0.0006
   -0.0036    0.0049    0.0016    0.1027    0.0018
   -0.0106    0.0176   -0.0006    0.0018    0.1031


mu =

    0.0076
    1.9786
    0.0035
   -2.9569
   -0.0123

</pre><h2>draw samples from posterior<a name="4"></a></h2><pre class="codeinput">iNumIter = 10000; <span class="comment">% number of samples</span>
<span class="keyword">for</span> iCount=1:iNumIter
    w_vector_array(iCount,:) = [mvnrnd(mu,lambda)];
<span class="keyword">end</span>
</pre><h2>get mean from posterior<a name="5"></a></h2><pre class="codeinput">size(w_vector_array)
disp(<span class="string">'inferred parameter vector (mean)'</span>)
[mean(w_vector_array(1:end,1)) mean(w_vector_array(1:end,2)) <span class="keyword">...</span>
    mean(w_vector_array(1:end,3))  mean(w_vector_array(1:end,4)) <span class="keyword">...</span>
    mean(w_vector_array(1:end,5)) ]
</pre><pre class="codeoutput">
ans =

       10000           5

inferred parameter vector (mean)

ans =

    0.0077    1.9785    0.0035   -2.9569   -0.0122

</pre><h2>plot histograms<a name="6"></a></h2><pre class="codeinput"><span class="keyword">if</span> iNumRegressors == 5
</pre><pre class="codeinput">    iNumBins = 100;
    figID = figure;
    subplot(2,3,1)
    hist(w_vector_array(1:end,1),iNumBins)
    hold <span class="string">on</span>
    subplot(2,3,2)
    hist(w_vector_array(1:end,2),iNumBins)
    hold <span class="string">on</span>
    subplot(2,3,3)
    hist(w_vector_array(1:end,3),iNumBins)
    hold <span class="string">on</span>
    subplot(2,3,4)
    hist(w_vector_array(1:end,4),iNumBins)
    hold <span class="string">on</span>
    subplot(2,3,[5 6])
    hist(w_vector_array(1:end,5),iNumBins)

    hold <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="bayesian_regression_01.png" alt=""> <h2>save plots<a name="8"></a></h2><pre class="codeinput">    print(figID, <span class="string">'-djpeg'</span>, sprintf(<span class="string">'bayesregression_parameters_hist%s.jpg'</span>, date));
</pre><img vspace="5" hspace="5" src="bayesian_regression_02.png" alt=""> <h2>plot Monte Carlo trace plots<a name="9"></a></h2><pre class="codeinput">    figID_2 = figure
    plot(w_vector_array(1:end,1))
    xlabel(<span class="string">'Monte Carlo samples'</span>); ylabel(<span class="string">'Posterior of one regressor parameter'</span>)
    print(figID_2, <span class="string">'-djpeg'</span>, sprintf(<span class="string">'mcmctrace_%s.jpg'</span>, date));
</pre><pre class="codeoutput">
figID_2 = 

  Figure (2) with properties:

      Number: 2
        Name: ''
       Color: [0.9400 0.9400 0.9400]
    Position: [360 278 560 420]
       Units: 'pixels'

  Use GET to show all properties

</pre><img vspace="5" hspace="5" src="bayesian_regression_03.png" alt=""> <pre class="codeinput"><span class="keyword">end</span>

toc;
</pre><pre class="codeoutput">Elapsed time is 3.993003 seconds.
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2014b</a><br></p></div><!--
##### SOURCE BEGIN #####
function bayesian_regression(X,Y,small_sigma_squared,eta_sqaured)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Name - bayesian_regression
% Creation Date - 3rd Nov 2014
% Author: Soumya Banerjee
% Website: https://sites.google.com/site/neelsoumya/
%
% Description: 
%   Function to do Bayesian regression
%   inspired by video on bayesian linear regression
%   https://www.youtube.com/watch?v=qz2U8coNwV4
%   by mathematicalmonk on youtube
%
% Input:  
%       X - matrix of predictors
%       Y - vector of responses
%       small_sigma_squared - standard deviation^2 (variance) for covariance matrix for Y
%       eta_sqaured - standard deviation^2 (variance) for covariance matrix for beta (regressors)
%   
% Output: 
%       1) Vector of inferred regressors/parameters  
%       2) Histograms of inferred regressors/parameters
%       3) Monte Carlo trace plots
%
% Assumptions -
%
% Example usage:
%   X = randn(100,5)
%   r = [0;2;0;-3;0] % only two nonzero coefficients
%   Y = X*r + randn(100,1)*.1 % small added noise
%   small_sigma_squared = 0.01
%   eta_sqaured = 0.01
%   bayesian_regression(X,Y,small_sigma_squared,eta_sqaured)
%
% License - BSD 
%
% Acknowledgements -
%           Dedicated to my wife Joyeeta Ghose and my mother Kalyani
%           Banerjee
%
% Change History - 
%                   3rd  Nov 2014  - Creation by Soumya Banerjee
%                   20th Nov 2014  - Modified by Soumya Banerjee
%                                       no burn-in required; hence taken
%                                       out (thanks to suggestion by
%                                       Alireza Kashani)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


tic;


%% do Bayesian regression
% beta is vector of regressors
% P(beta|D) ~ N(beta| mu, lambda)
% mu = lambda * X{transpose} * big_sigma^(-1) * Y
% lambda = (X{transpose} * inv(sigma) * X + inv(big_omega))^{-1}
% $P(\beta|D) \sim N(\beta| \mu, \lambda)$
% $\mu = \Lambda * X^{T} * \Sigma^{-1} * Y$ 
% $\Lambda = (X^{T} * \Sigma^{-1} * X + \Omega^{-1})^{-1}$

iNumMeasurements = size(X,1);
iNumRegressors   = size(X,2);

big_sigma = small_sigma_squared * eye(iNumMeasurements); %a = 0.01 * eye(5);
big_omega = eta_sqaured * eye(iNumRegressors); %b = 0.01 * eye(5);

disp('covariance matrix and mean vector of posterior distribution')
lambda = inv(X' * inv(big_sigma) * X + inv(big_omega))
mu     = lambda * X' * inv(big_sigma) * Y

% mvnrnd(MU,SIGMA)
% mvnrnd(mu,lambda)
%% draw samples from posterior
iNumIter = 10000; % number of samples
for iCount=1:iNumIter
    w_vector_array(iCount,:) = [mvnrnd(mu,lambda)];
end

%% get mean from posterior
size(w_vector_array)
disp('inferred parameter vector (mean)')
[mean(w_vector_array(1:end,1)) mean(w_vector_array(1:end,2)) ...
    mean(w_vector_array(1:end,3))  mean(w_vector_array(1:end,4)) ...
    mean(w_vector_array(1:end,5)) ]


%% plot histograms
if iNumRegressors == 5
    iNumBins = 100;
    figID = figure;
    subplot(2,3,1)
    hist(w_vector_array(1:end,1),iNumBins)
    hold on
    subplot(2,3,2)
    hist(w_vector_array(1:end,2),iNumBins)
    hold on
    subplot(2,3,3)
    hist(w_vector_array(1:end,3),iNumBins)
    hold on
    subplot(2,3,4)
    hist(w_vector_array(1:end,4),iNumBins)
    hold on
    subplot(2,3,[5 6])
    hist(w_vector_array(1:end,5),iNumBins)

    hold off

    %% save plots
    print(figID, '-djpeg', sprintf('bayesregression_parameters_hist%s.jpg', date));
    
    %% plot Monte Carlo trace plots
    figID_2 = figure
    plot(w_vector_array(1:end,1))
    xlabel('Monte Carlo samples'); ylabel('Posterior of one regressor parameter')
    print(figID_2, '-djpeg', sprintf('mcmctrace_%s.jpg', date));
end

toc;



##### SOURCE END #####
--></body></html>